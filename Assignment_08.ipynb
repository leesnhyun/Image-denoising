{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\title{assignment 08}\n",
    "\\author{SengHyun Lee}\n",
    "\\date{2019.12.12}\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a denoising algorithm based on an auto-encoder architecture using pytorch library in the supervised learning framework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Denoising aims to reconstruct a clean image from a noisy observation\n",
    "- We use a simple additive noise model using the Normal distribution:\n",
    "\n",
    "    $f = u + \\eta$\n",
    "    \n",
    "    where $f$ denotes a noisy observation, $u$ denotes a desired clean reconstruction, and $\\eta$ denotes a noise process following the normal distribution:\n",
    "\n",
    "    $\\eta \\sim N(0, \\sigma^2)$\n",
    "\n",
    "    where $N(0, \\sigma^2)$ denotes the normal distribution with mean 0 and standard deviation $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function \n",
    "\n",
    "- My train loss function:\n",
    "\n",
    "    $\\ell(h, \\hat{h}) = \\frac{1}{m}\\sum_{n=1}^{m}{\\| h_{n} - \\hat{h}_{n} \\|_2^2}$\n",
    "\n",
    "- $h$ denotes a clean ground truth and $\\hat{h}$ denotes an output of the network\n",
    "- $m$ denotes mini-batch size  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters\n",
    "\n",
    "- learning rate : 1e-3\n",
    "- batch size : 4\n",
    "- optimizer : Adam Optimizer\n",
    "- max number of epoch : 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVmFa0_UndLb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1amYPATWmRY"
   },
   "outputs": [],
   "source": [
    "# custom dataloader for .npy file\n",
    "class numpyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_plot(g1, std, title, color, scale, label, legend):\n",
    "    plt.title(title)\n",
    "    plt.plot(np.arange(1, len(g1) + 1), g1, color=color[0], alpha=0.5, label=label)\n",
    "    if scale is not None:\n",
    "        plt.yscale(scale)\n",
    "    if std is not None:\n",
    "        plt.fill_between(np.arange(1, len(g1)+1),\n",
    "                         np.array(g1)-np.array(std),\n",
    "                         np.array(g1)+np.array(std), color=color[0], alpha=0.3)\n",
    "    plt.legend(loc=legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBjyiqXqnj-c"
   },
   "outputs": [],
   "source": [
    "class DenoiseNetwork(nn.Module):\n",
    "    def __init__(self, depth=17, n_channels=64, image_channels=1, kernel_size=3):\n",
    "        super(DenoiseNetwork, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        encoder_layers = []\n",
    "\n",
    "        encoder_layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
    "        encoder_layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(depth-2):\n",
    "            encoder_layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "            encoder_layers.append(nn.BatchNorm2d(n_channels, momentum = 0.95))\n",
    "            encoder_layers.append(nn.ReLU(inplace=True))\n",
    "        encoder_layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "       \n",
    "        self.auto_encode = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.auto_encode(x)\n",
    "        return y-out\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orPzbm3fnmyJ"
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "model = DenoiseNetwork()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)\n",
    "objective = nn.MSELoss(reduction = 'sum')\n",
    "\n",
    "\n",
    "loss_train = []\n",
    "to_img = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUEI3UXuWmRb"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 30\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# for training\n",
    "traindata = np.load('train.npy')\n",
    "traindataset = numpyDataset(traindata, transform)\n",
    "trainloader = DataLoader(traindataset, batch_size=4, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "loss_train_mean, loss_train_std = [], []\n",
    "prev_train_loss, next_train_loss = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZgpPhtinqz5"
   },
   "outputs": [],
   "source": [
    "def train(batch_idx, epoch, clean_image, noisy_image):\n",
    "    clean, noisy = Variable(clean_image).cuda(), Variable(noisy_image).cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(noisy)\n",
    "\n",
    "    loss = objective(output, clean)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(epoch)\n",
    "    \n",
    "    loss_train_batch = loss.item() / len(data)\n",
    "\n",
    "    return loss_train_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skUibzj8WmRd",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] loss(training): 38.135274913907054\n",
      "[epoch 1] loss(training): 4.239182426225056\n",
      "[epoch 2] loss(training): 3.592938362956047\n",
      "[epoch 3] loss(training): 3.439420774633234\n",
      "[epoch 4] loss(training): 3.1291519671407615\n",
      "[epoch 5] loss(training): 3.0552961523695426\n",
      "[epoch 6] loss(training): 2.8136225374720314\n",
      "[epoch 7] loss(training): 2.7243282652172174\n",
      "[epoch 8] loss(training): 2.59743206016042\n",
      "[epoch 9] loss(training): 2.2674315757914023\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(NUM_EPOCH):\n",
    "\n",
    "    batch_train_loss = []\n",
    "\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        \n",
    "        # Noisy Images #\n",
    "        samples = [\n",
    "            data + (0.01 * torch.randn(len(data), 1, 120, 80)),\n",
    "            data + (0.02 * torch.randn(len(data), 1, 120, 80)),\n",
    "            data + (0.03 * torch.randn(len(data), 1, 120, 80)),\n",
    "            data + (0.04 * torch.randn(len(data), 1, 120, 80))\n",
    "        ]\n",
    "        ########\n",
    "\n",
    "        loss_train = train(batch_idx, epoch, data, samples[random.randint(0, 3)])\n",
    "\n",
    "        batch_train_loss.append(loss_train)\n",
    "\n",
    "    loss_train_mean.append(np.mean(batch_train_loss))\n",
    "    loss_train_std.append(np.std(batch_train_loss))\n",
    "\n",
    "    print(\"[epoch %s] loss(training): %s\" % (epoch, loss_train_mean[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plot(loss_train_mean, std=None, title=\"Loss\", scale=None, color=('blue'), label='train loss', legend='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plot(loss_train_mean, std=loss_train_std, title=\"Loss with std (log scale)\", color=('blue'), scale='log', label='train loss with std', legend='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(trainloader):\n",
    "        # Noisy Images #\n",
    "        sample = data + (0.04 * torch.randn(len(data), 1, 120, 80))\n",
    "        \n",
    "        fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(9, 7))\n",
    "        ax[0].set_title(\"Clean\")\n",
    "        ax[1].set_title(\"Noisy(input)\")\n",
    "        ax[2].set_title(\"Denoised\")\n",
    "\n",
    "        ax[0].imshow(to_img(data[0].cpu()), cmap='gray')\n",
    "        ax[1].imshow(to_img(sample[0].cpu()), cmap='gray')\n",
    "        ax[2].imshow(to_img(model(Variable(data).cuda())[0].cpu()), cmap='gray')\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLL9kyTBWmRf"
   },
   "outputs": [],
   "source": [
    "# for testing\n",
    "testdata = np.load('test.npy')\n",
    "testdataset = numpyDataset(testdata, transform)\n",
    "testloader = DataLoader(testdataset, batch_size=1, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "result_for_submit = None  # this is for submit file\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, data in enumerate(testloader):\n",
    "    result_of_test = data\n",
    "\n",
    "    if batch_idx == 0:\n",
    "        result_for_submit = result_of_test\n",
    "    else:\n",
    "        try:\n",
    "            result_for_submit = torch.cat([result_for_submit, result_of_test], dim=0)\n",
    "\n",
    "        except RuntimeError:\n",
    "            transposed = torch.transpose(result_of_test, 2, 3)\n",
    "            result_for_submit = torch.cat([result_for_submit, transposed], dim=0)\n",
    "\n",
    "# the submit_file.shape must be (400,1,120,80)\n",
    "submit_file = result_for_submit.detach().numpy()\n",
    "print(submit_file.shape)\n",
    "\n",
    "np.save('20142921_08_SengHyun_Lee.npy', submit_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(testloader):\n",
    "    \n",
    "        fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(9, 7))\n",
    "        ax[0].set_title(\"Noisy\")\n",
    "        ax[1].set_title(\"Denoised\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(7,9))\n",
    "            result_of_test = model.forward(data.cuda())\n",
    "            ax[0].imshow(to_img(data[0].cpu()), cmap='gray')\n",
    "            ax[1].imshow(to_img(result_of_test[0].cpu()), cmap='gray')\n",
    "            fig.show()\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 08-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
