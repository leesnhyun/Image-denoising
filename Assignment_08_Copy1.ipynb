{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Assignment 08-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHXZlcUrXEpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVmFa0_UndLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1amYPATWmRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom dataloader for .npy file\n",
        "class numpyDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = torch.from_numpy(data).float()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBjyiqXqnj-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenoiseNetwork(nn.Module):\n",
        "    def __init__(self, depth=17, n_channels=64, image_channels=1, kernel_size=3):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        encoder_layers = []\n",
        "\n",
        "        encoder_layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
        "        encoder_layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(depth-2):\n",
        "            encoder_layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            encoder_layers.append(nn.BatchNorm2d(n_channels, momentum = 0.95))\n",
        "            encoder_layers.append(nn.ReLU(inplace=True))\n",
        "        encoder_layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        encoder_layers.append(nn.Conv2d(1, 1, 1))\n",
        "        \n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "        self.decoder = nn.Sequential(nn.ConvTranspose2d(1, 1, 1))\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "        return y-out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.orthogonal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orPzbm3fnmyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import model\n",
        "model = DenoiseNetwork()\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)\n",
        "objective = nn.MSELoss(reduction = 'sum')\n",
        "\n",
        "\n",
        "loss_train = []\n",
        "to_img = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUEI3UXuWmRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCH = 100\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# for training\n",
        "traindata = np.load('/content/drive/My Drive/Colab Notebooks/train.npy')\n",
        "traindataset = numpyDataset(traindata, transform)\n",
        "trainloader = DataLoader(traindataset, batch_size=4, shuffle=True, drop_last=True, num_workers=2)\n",
        "\n",
        "loss_train_mean, loss_train_std = [], []\n",
        "prev_train_loss, next_train_loss = 0, 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZgpPhtinqz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(batch_idx, epoch, clean_image, noisy_image):\n",
        "    clean, noisy = Variable(clean_image).cuda(), Variable(noisy_image).cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(noisy)\n",
        "\n",
        "    loss = objective(output, clean)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step(epoch)\n",
        "    \n",
        "    loss_train_batch = loss.item() / len(data)\n",
        "\n",
        "    return loss_train_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "skUibzj8WmRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(9, 7))\n",
        "ax[0].set_title(\"Clean\")\n",
        "ax[1].set_title(\"Noisy(input)\")\n",
        "ax[2].set_title(\"Denoised\")\n",
        "\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCH):\n",
        "\n",
        "    batch_train_loss = []\n",
        "\n",
        "    for batch_idx, data in enumerate(trainloader):\n",
        "        \n",
        "        # Noisy Images #\n",
        "        samples = [\n",
        "            data + (0.01 * torch.randn(len(data), 1, 120, 80)),\n",
        "            data + (0.02 * torch.randn(len(data), 1, 120, 80)),\n",
        "            data + (0.03 * torch.randn(len(data), 1, 120, 80)),\n",
        "            data + (0.04 * torch.randn(len(data), 1, 120, 80))\n",
        "        ]\n",
        "        ########\n",
        "\n",
        "        loss_train = train(batch_idx, epoch, data, samples[random.randint(0, 3)])\n",
        "\n",
        "        batch_train_loss.append(loss_train)\n",
        "\n",
        "    loss_train_mean.append(np.mean(batch_train_loss))\n",
        "    loss_train_std.append(np.std(batch_train_loss))\n",
        "\n",
        "    print(\"[epoch %s] loss(training): %s\" % (epoch, loss_train_mean[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLL9kyTBWmRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for testing\n",
        "testdata = np.load('/content/drive/My Drive/Colab Notebooks/test.npy')\n",
        "testdataset = numpyDataset(testdata, transform)\n",
        "testloader = DataLoader(testdataset, batch_size=1, shuffle=False, drop_last=False, num_workers=2)\n",
        "\n",
        "result_for_submit = None  # this is for submit file\n",
        "\n",
        "model.eval()\n",
        "to_img = transforms.ToPILImage()\n",
        "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(9, 7))\n",
        "for batch_idx, data in enumerate(testloader):\n",
        "    result_of_test = data\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(7,9))\n",
        "        result_of_test = model.forward(data.cuda())\n",
        "        ax[0].imshow(to_img(data[0].cpu()), cmap='gray')\n",
        "        ax[1].imshow(to_img(y[0].cpu()), cmap='gray')\n",
        "        fig.show()\n",
        "\n",
        "    if batch_idx == 0:\n",
        "        result_for_submit = result_of_test\n",
        "    else:\n",
        "        try:\n",
        "            result_for_submit = torch.cat([result_for_submit, result_of_test], dim=0)\n",
        "\n",
        "        except RuntimeError:\n",
        "            transposed = torch.transpose(result_of_test, 2, 3)\n",
        "            result_for_submit = torch.cat([result_for_submit, transposed], dim=0)\n",
        "\n",
        "# the submit_file.shape must be (400,1,120,80)\n",
        "submit_file = result_for_submit.detach().numpy()\n",
        "print(submit_file.shape)\n",
        "np.save('your_name.npy', submit_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}